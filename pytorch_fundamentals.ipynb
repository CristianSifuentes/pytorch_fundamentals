{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ce2f70d",
   "metadata": {},
   "source": [
    "# Mastering PyTorch: Fundamental Concepts for Machine Learning\n",
    "This Google Colab notebook walks through **basic â†’ advanced** PyTorch featuresâ€”the same tools used to train cuttingâ€‘edge research models.\n",
    "\n",
    "*Author: ChatGPTâ€‘4o*  \n",
    "*Last updated:* 2025-06-29 00:57 UTC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74569702",
   "metadata": {},
   "source": [
    "## Environment Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816a596e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch, platform, sys, time, math\n",
    "print(f'PyTorch version: {torch.__version__}')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9238acfe",
   "metadata": {},
   "source": [
    "## 1. Tensor Essentials\n",
    "Tensors are multiâ€‘dimensional arraysâ€”the basic building blocks of every PyTorch model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb58ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creating tensors\n",
    "import torch\n",
    "scalar = torch.tensor(3.14)\n",
    "vector = torch.tensor([1,2,3])\n",
    "matrix = torch.randn((3,3))\n",
    "tensor4d = torch.zeros((2,3,4,5))\n",
    "\n",
    "print('Scalar:', scalar)\n",
    "print('Vector:', vector)\n",
    "print('Matrix shape:', matrix.shape)\n",
    "print('4â€‘D Tensor shape:', tensor4d.shape)\n",
    "\n",
    "# Tensor math\n",
    "a = torch.randn((2,2))\n",
    "b = torch.randn((2,2))\n",
    "print('Matrix product:\\n', a @ b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e76a81",
   "metadata": {},
   "source": [
    "### Device placement\n",
    "Move tensors between CPU and GPU seamlessly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3a6868",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "matrix_gpu = matrix.to(device)\n",
    "print('matrix_gpu device ->', matrix_gpu.device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58537177",
   "metadata": {},
   "source": [
    "## 2. Autograd: Automatic Differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afffe8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = torch.tensor([2.0, 3.0], requires_grad=True)\n",
    "y = (x**2).sum()\n",
    "y.backward()\n",
    "print('Gradients:', x.grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc7be7f",
   "metadata": {},
   "source": [
    "## 3. Build & Train a Simple Neural Network\n",
    "We'll create a small MLP to classify twoâ€‘moon data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f30d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# generate data\n",
    "X, y = make_moons(n_samples=2000, noise=0.25, random_state=42)\n",
    "X = StandardScaler().fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test  = torch.tensor(X_test , dtype=torch.float32)\n",
    "y_test  = torch.tensor(y_test , dtype=torch.long)\n",
    "\n",
    "train_ds = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "test_ds  = torch.utils.data.TensorDataset(X_test , y_test )\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "test_loader  = torch.utils.data.DataLoader(test_ds , batch_size=64)\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(2, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32,16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16,2)\n",
    "        )\n",
    "    def forward(self,x): return self.net(x)\n",
    "\n",
    "model = MLP().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
    "\n",
    "# Training loop with mixed precision\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(device.type=='cuda'))\n",
    "\n",
    "for epoch in range(1,51):\n",
    "    model.train()\n",
    "    running_loss=0.0\n",
    "    for xb,yb in train_loader:\n",
    "        xb,yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n",
    "            preds = model(xb)\n",
    "            loss = criterion(preds,yb)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        running_loss += loss.item()*xb.size(0)\n",
    "    scheduler.step()\n",
    "    if epoch%10==0:\n",
    "        print(f'Epoch {epoch:02d} | Loss {running_loss/len(train_ds):.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6286f346",
   "metadata": {},
   "source": [
    "## 4. Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b47e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.eval()\n",
    "correct,total = 0,0\n",
    "with torch.no_grad():\n",
    "    for xb,yb in test_loader:\n",
    "        xb,yb = xb.to(device), yb.to(device)\n",
    "        preds = model(xb).argmax(1)\n",
    "        correct += (preds==yb).sum().item()\n",
    "        total += yb.size(0)\n",
    "print(f'Test Accuracy: {correct/total*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832687e4",
   "metadata": {},
   "source": [
    "## 5. Custom Autograd Function\n",
    "Create a custom activation (Swish) with manual backward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e60247",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Swish(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x):\n",
    "        ctx.save_for_backward(x)\n",
    "        return x * torch.sigmoid(x)\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        x, = ctx.saved_tensors\n",
    "        sig = torch.sigmoid(x)\n",
    "        return grad_output * (sig + x*sig*(1-sig))\n",
    "\n",
    "# test\n",
    "x = torch.randn(5, requires_grad=True)\n",
    "y = Swish.apply(x)\n",
    "y.sum().backward()\n",
    "print('Custom gradient ok:', x.grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82e528e",
   "metadata": {},
   "source": [
    "## 6. Saving, Loading, and TorchScript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e17c9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.save(model.state_dict(), 'mlp_moons.pth')\n",
    "# Recreate & load\n",
    "loaded = MLP().to(device)\n",
    "loaded.load_state_dict(torch.load('mlp_moons.pth', map_location=device))\n",
    "\n",
    "# TorchScript trace\n",
    "scripted = torch.jit.script(loaded)\n",
    "scripted.save('mlp_moons_scripted.pt')\n",
    "print('Model scripted & saved.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23909a8d",
   "metadata": {},
   "source": [
    "## ðŸŽ‰ Conclusion\n",
    "This notebook covered:\n",
    "- **Tensors** & device placement\n",
    "- **Autograd** and custom gradients\n",
    "- **Adam optimizer**, LR scheduler, mixed precision\n",
    "- **GPU acceleration**\n",
    "- Saving, loading, and *TorchScript*\n",
    "\n",
    "Experiment further by increasing model depth, trying different optimizers, or scaling up on more complex datasets!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
